"""
ğŸ¯ äº¤äº’å¼ç”Ÿç‰©æ•°æ®é¢„æµ‹ç³»ç»Ÿ
åŠŸèƒ½ï¼šä¸Šä¼ Excelæ–‡ä»¶ã€æ•°æ®æ¢ç´¢ã€æ¨¡å‹è®­ç»ƒã€äº¤äº’å¼é¢„æµ‹ã€å¯è§†åŒ–
ä½œè€…ï¼šä¿®å‡¯sey
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
import os
import tempfile
import joblib
import warnings

warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             mean_squared_error, mean_absolute_error, r2_score,
                             confusion_matrix, classification_report, roc_curve, auc)
from sklearn.ensemble import (RandomForestClassifier, RandomForestRegressor,
                              GradientBoostingClassifier, GradientBoostingRegressor,
                              AdaBoostClassifier, AdaBoostRegressor)
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso
from sklearn.svm import SVC, SVR
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb
import lightgbm as lgb

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ§¬ ç”Ÿç‰©æ•°æ®é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #2E86C1;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #3498DB;
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    .success-box {
        background-color: #D5F5E3;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #27AE60;
    }
    .warning-box {
        background-color: #FDEBD0;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #F39C12;
    }
    .info-box {
        background-color: #D6EAF8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #3498DB;
    }
    .metric-card {
        background-color: #F8F9F9;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #D5D8DC;
        text-align: center;
    }
    .stButton>button {
        background-color: #2E86C1;
        color: white;
        font-weight: bold;
        border-radius: 0.5rem;
        padding: 0.5rem 1rem;
        border: none;
    }
    .stButton>button:hover {
        background-color: #3498DB;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'datasets' not in st.session_state:
    st.session_state.datasets = {}
if 'current_dataset' not in st.session_state:
    st.session_state.current_dataset = None
if 'model' not in st.session_state:
    st.session_state.model = None
if 'scaler' not in st.session_state:
    st.session_state.scaler = None
if 'label_encoders' not in st.session_state:
    st.session_state.label_encoders = {}

# åº”ç”¨æ ‡é¢˜
st.markdown('<h1 class="main-header">ğŸ§¬ äº¤äº’å¼ç”Ÿç‰©æ•°æ®é¢„æµ‹ç³»ç»Ÿ</h1>', unsafe_allow_html=True)
st.markdown("""
<div class="info-box">
    <b>ç³»ç»ŸåŠŸèƒ½ï¼š</b>ä¸Šä¼ Excelæ–‡ä»¶ â†’ æ•°æ®æ¢ç´¢ â†’ æ•°æ®é¢„å¤„ç† â†’ æ¨¡å‹è®­ç»ƒ â†’ äº¤äº’å¼é¢„æµ‹ â†’ å¯è§†åŒ–åˆ†æ
</div>
""", unsafe_allow_html=True)

# ä¾§è¾¹æ å¯¼èˆª
st.sidebar.title("ğŸ“‹ å¯¼èˆª")
page = st.sidebar.radio(
    "é€‰æ‹©åŠŸèƒ½",
    ["ğŸ  é¦–é¡µ", "ğŸ“¤ ä¸Šä¼ æ•°æ®", "ğŸ” æ•°æ®æ¢ç´¢", "ğŸ§¹ æ•°æ®é¢„å¤„ç†",
     "ğŸ¤– æ¨¡å‹è®­ç»ƒ", "ğŸ“Š æ¨¡å‹è¯„ä¼°", "ğŸ”® äº¤äº’å¼é¢„æµ‹", "ğŸ’¾ æ¨¡å‹ç®¡ç†"]
)

# ==================== é¦–é¡µ ====================
if page == "ğŸ  é¦–é¡µ":
    st.markdown('<h2 class="sub-header">æ¬¢è¿ä½¿ç”¨ç”Ÿç‰©æ•°æ®é¢„æµ‹ç³»ç»Ÿ</h2>', unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ“¤ æ•°æ®ä¸Šä¼ </h3>
            <p>æ”¯æŒå¤šä¸ªExcelæ–‡ä»¶åŒæ—¶ä¸Šä¼ </p>
            <p>è‡ªåŠ¨æ£€æµ‹æ•°æ®æ ¼å¼</p>
            <p>æ”¯æŒæ•°æ®é¢„è§ˆ</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ” æ™ºèƒ½åˆ†æ</h3>
            <p>è‡ªåŠ¨æ•°æ®æ¢ç´¢</p>
            <p>å¯è§†åŒ–ç»Ÿè®¡åˆ†æ</p>
            <p>ç¼ºå¤±å€¼æ£€æµ‹</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ¤– æœºå™¨å­¦ä¹ </h3>
            <p>å¤šç§é¢„æµ‹æ¨¡å‹</p>
            <p>è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–</p>
            <p>äº¤å‰éªŒè¯è¯„ä¼°</p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # ä½¿ç”¨æŒ‡å—
    st.markdown('<h3>ğŸ“š ä½¿ç”¨æŒ‡å—</h3>', unsafe_allow_html=True)

    steps = [
        ("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ•°æ®", "åœ¨'ä¸Šä¼ æ•°æ®'é¡µé¢é€‰æ‹©æ‚¨çš„Excelæ–‡ä»¶ï¼Œæ”¯æŒæ‰¹é‡ä¸Šä¼ "),
        ("ç¬¬äºŒæ­¥ï¼šæ•°æ®æ¢ç´¢", "åœ¨'æ•°æ®æ¢ç´¢'é¡µé¢æŸ¥çœ‹æ•°æ®ç»Ÿè®¡ä¿¡æ¯ã€åˆ†å¸ƒå’Œç›¸å…³æ€§"),
        ("ç¬¬ä¸‰æ­¥ï¼šæ•°æ®é¢„å¤„ç†", "å¤„ç†ç¼ºå¤±å€¼ã€ç¼–ç åˆ†ç±»å˜é‡ã€ç‰¹å¾ç¼©æ”¾ç­‰"),
        ("ç¬¬å››æ­¥ï¼šæ¨¡å‹è®­ç»ƒ", "é€‰æ‹©ç®—æ³•ã€è°ƒæ•´å‚æ•°ã€è®­ç»ƒé¢„æµ‹æ¨¡å‹"),
        ("ç¬¬äº”æ­¥ï¼šæ¨¡å‹è¯„ä¼°", "æŸ¥çœ‹æ¨¡å‹æ€§èƒ½æŒ‡æ ‡å’Œå¯è§†åŒ–ç»“æœ"),
        ("ç¬¬å…­æ­¥ï¼šäº¤äº’å¼é¢„æµ‹", "ä½¿ç”¨æ»‘å—å’Œè¾“å…¥æ¡†è¿›è¡Œå®æ—¶é¢„æµ‹"),
        ("ç¬¬ä¸ƒæ­¥ï¼šæ¨¡å‹ç®¡ç†", "ä¿å­˜å’ŒåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹")
    ]

    for i, (title, desc) in enumerate(steps, 1):
        with st.expander(f"ç¬¬{i}æ­¥ï¼š{title}"):
            st.write(desc)

    # æ”¯æŒçš„æ•°æ®æ ¼å¼
    st.markdown('<h3>ğŸ“ æ”¯æŒçš„æ•°æ®æ ¼å¼</h3>', unsafe_allow_html=True)
    st.write("""
    - **æ–‡ä»¶æ ¼å¼**: .xlsx, .xls, .csv
    - **æ•°æ®ç±»å‹**: æ•°å€¼å‹ã€åˆ†ç±»å‹ã€æ—¶é—´åºåˆ—
    - **æ•°æ®è§„æ¨¡**: æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†ï¼ˆè‡ªåŠ¨åˆ†å—å¤„ç†ï¼‰
    - **ç‰¹æ®Šå¤„ç†**: è‡ªåŠ¨å¤„ç†åˆå¹¶å•å…ƒæ ¼ã€ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼
    """)

    # å¿«é€Ÿå¼€å§‹æŒ‰é’®
    st.markdown("---")
    if st.button("ğŸš€ å¿«é€Ÿå¼€å§‹", use_container_width=True):
        st.session_state.page = "ğŸ“¤ ä¸Šä¼ æ•°æ®"
        st.rerun()

# ==================== ä¸Šä¼ æ•°æ® ====================
elif page == "ğŸ“¤ ä¸Šä¼ æ•°æ®":
    st.markdown('<h2 class="sub-header">ğŸ“¤ ä¸Šä¼ Excelæ•°æ®æ–‡ä»¶</h2>', unsafe_allow_html=True)

    # ä¸Šä¼ æ–‡ä»¶
    uploaded_files = st.file_uploader(
        "é€‰æ‹©Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼‰",
        type=['xlsx', 'xls', 'csv'],
        accept_multiple_files=True,
        help="å¯ä»¥ä¸Šä¼ å¤šä¸ªExcelæ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆå¹¶æˆ–åˆ†åˆ«å¤„ç†"
    )

    if uploaded_files:
        st.markdown(f'<div class="success-box">âœ… å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶</div>', unsafe_allow_html=True)

        # å¤„ç†æ¯ä¸ªä¸Šä¼ çš„æ–‡ä»¶
        for uploaded_file in uploaded_files:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)

                # å­˜å‚¨åˆ°session state
                st.session_state.datasets[uploaded_file.name] = {
                    'df': df,
                    'shape': df.shape,
                    'columns': list(df.columns),
                    'dtypes': df.dtypes.to_dict()
                }

                st.success(f"âœ… æ–‡ä»¶ '{uploaded_file.name}' åŠ è½½æˆåŠŸï¼")

                # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                with st.expander(f"ğŸ“‹ {uploaded_file.name} - æ•°æ®é¢„è§ˆ"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**æ•°æ®å½¢çŠ¶**: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
                        st.write(f"**æ–‡ä»¶å¤§å°**: {uploaded_file.size / 1024:.2f} KB")
                    with col2:
                        st.write(f"**ç¼ºå¤±å€¼æ€»æ•°**: {df.isnull().sum().sum()}")
                        st.write(f"**é‡å¤è¡Œæ•°**: {df.duplicated().sum()}")

                    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                    st.write("**æ•°æ®é¢„è§ˆ**:")
                    st.dataframe(df.head(), use_container_width=True)

                    # æ˜¾ç¤ºåˆ—ä¿¡æ¯
                    st.write("**åˆ—ä¿¡æ¯**:")
                    col_info = pd.DataFrame({
                        'åˆ—å': df.columns,
                        'æ•°æ®ç±»å‹': df.dtypes.values,
                        'éç©ºå€¼æ•°é‡': df.notnull().sum().values,
                        'ç¼ºå¤±å€¼æ•°é‡': df.isnull().sum().values,
                        'ç¼ºå¤±ç‡%': (df.isnull().sum().values / len(df) * 100).round(2)
                    })
                    st.dataframe(col_info, use_container_width=True)

            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶ '{uploaded_file.name}' åŠ è½½å¤±è´¥: {str(e)}")

        # é€‰æ‹©å½“å‰æ“ä½œçš„æ•°æ®é›†
        if st.session_state.datasets:
            dataset_names = list(st.session_state.datasets.keys())
            selected_dataset = st.selectbox(
                "é€‰æ‹©è¦æ“ä½œçš„æ•°æ®é›†",
                dataset_names,
                help="é€‰æ‹©è¦è¿›è¡Œæ¢ç´¢ã€é¢„å¤„ç†å’Œå»ºæ¨¡çš„æ•°æ®é›†"
            )
            st.session_state.current_dataset = selected_dataset

            # æ˜¾ç¤ºé€‰ä¸­çš„æ•°æ®é›†ä¿¡æ¯
            if selected_dataset:
                dataset_info = st.session_state.datasets[selected_dataset]
                st.markdown(
                    f'<div class="info-box">å½“å‰é€‰æ‹©: <b>{selected_dataset}</b> | å½¢çŠ¶: {dataset_info["shape"]}</div>',
                    unsafe_allow_html=True)

    else:
        st.markdown('<div class="warning-box">âš ï¸ è¯·ä¸Šä¼ Excelæˆ–CSVæ–‡ä»¶å¼€å§‹åˆ†æ</div>', unsafe_allow_html=True)

        # æä¾›ç¤ºä¾‹æ•°æ®ä¸‹è½½
        st.write("### éœ€è¦ç¤ºä¾‹æ•°æ®ï¼Ÿ")
        if st.button("ä¸‹è½½ç¤ºä¾‹æ•°æ®"):
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            sample_data = pd.DataFrame({
                'æ ·æœ¬ID': [f'Sample_{i}' for i in range(1, 101)],
                'åŸºå› è¡¨è¾¾é‡_A': np.random.normal(10, 2, 100),
                'åŸºå› è¡¨è¾¾é‡_B': np.random.normal(15, 3, 100),
                'åŸºå› è¡¨è¾¾é‡_C': np.random.normal(8, 1.5, 100),
                'å¹´é¾„': np.random.randint(20, 70, 100),
                'æ€§åˆ«': np.random.choice(['ç”·', 'å¥³'], 100),
                'æ²»ç–—æ–¹æ¡ˆ': np.random.choice(['Aç»„', 'Bç»„', 'å¯¹ç…§ç»„'], 100),
                'ç–¾ç—…çŠ¶æ€': np.random.choice([0, 1], 100, p=[0.7, 0.3]),
                'ç”Ÿå­˜æ—¶é—´(å¤©)': np.random.exponential(365, 100)
            })

            # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼
            for col in sample_data.columns[1:-2]:
                mask = np.random.random(100) < 0.05
                sample_data.loc[mask, col] = np.nan

            # æä¾›ä¸‹è½½
            csv = sample_data.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç¤ºä¾‹æ•°æ® (CSV)",
                data=csv,
                file_name="ç”Ÿç‰©æ•°æ®ç¤ºä¾‹.csv",
                mime="text/csv",
            )

# ==================== æ•°æ®æ¢ç´¢ ====================
elif page == "ğŸ” æ•°æ®æ¢ç´¢":
    st.markdown('<h2 class="sub-header">ğŸ” æ•°æ®æ¢ç´¢ä¸åˆ†æ</h2>', unsafe_allow_html=True)

    if not st.session_state.datasets:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        st.stop()

    # é€‰æ‹©æ•°æ®é›†
    dataset_names = list(st.session_state.datasets.keys())
    selected_dataset = st.selectbox(
        "é€‰æ‹©è¦æ¢ç´¢çš„æ•°æ®é›†",
        dataset_names,
        index=dataset_names.index(st.session_state.current_dataset) if st.session_state.current_dataset else 0
    )

    if selected_dataset:
        df = st.session_state.datasets[selected_dataset]['df']
        st.session_state.current_dataset = selected_dataset

        # æ¢ç´¢é€‰é¡¹
        explore_options = st.multiselect(
            "é€‰æ‹©æ¢ç´¢åŠŸèƒ½",
            ["ğŸ“Š åŸºæœ¬ç»Ÿè®¡", "ğŸ“ˆ æ•°æ®åˆ†å¸ƒ", "ğŸ”— ç›¸å…³æ€§åˆ†æ", "ğŸ“‰ ç¼ºå¤±å€¼åˆ†æ", "ğŸ¯ ç›®æ ‡å˜é‡åˆ†æ", "ğŸ”„ æ•°æ®å˜æ¢"],
            default=["ğŸ“Š åŸºæœ¬ç»Ÿè®¡", "ğŸ“ˆ æ•°æ®åˆ†å¸ƒ"]
        )

        # 1. åŸºæœ¬ç»Ÿè®¡
        if "ğŸ“Š åŸºæœ¬ç»Ÿè®¡" in explore_options:
            st.markdown('<h3>ğŸ“Š åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯</h3>', unsafe_allow_html=True)

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»è¡Œæ•°", len(df))
            with col2:
                st.metric("æ€»åˆ—æ•°", len(df.columns))
            with col3:
                st.metric("æ€»ç¼ºå¤±å€¼", df.isnull().sum().sum())

            # æ•°å€¼å‹ç»Ÿè®¡
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                st.write("**æ•°å€¼å‹å˜é‡ç»Ÿè®¡**:")
                st.dataframe(df[numeric_cols].describe().T, use_container_width=True)

            # åˆ†ç±»å‹ç»Ÿè®¡
            categorical_cols = df.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                st.write("**åˆ†ç±»å‹å˜é‡ç»Ÿè®¡**:")
                cat_stats = {}
                for col in categorical_cols:
                    cat_stats[col] = {
                        'ç±»åˆ«æ•°': df[col].nunique(),
                        'æœ€å¸¸è§å€¼': df[col].mode()[0] if not df[col].mode().empty else None,
                        'æœ€å¸¸è§é¢‘æ•°': df[col].value_counts().iloc[0] if not df[col].value_counts().empty else 0
                    }
                st.dataframe(pd.DataFrame(cat_stats).T, use_container_width=True)

        # 2. æ•°æ®åˆ†å¸ƒ
        if "ğŸ“ˆ æ•°æ®åˆ†å¸ƒ" in explore_options:
            st.markdown('<h3>ğŸ“ˆ æ•°æ®åˆ†å¸ƒå¯è§†åŒ–</h3>', unsafe_allow_html=True)

            # é€‰æ‹©è¦å¯è§†åŒ–çš„åˆ—
            all_cols = list(df.columns)
            viz_cols = st.multiselect("é€‰æ‹©è¦å¯è§†åŒ–çš„åˆ—", all_cols, default=all_cols[:min(5, len(all_cols))])

            if viz_cols:
                # åˆ›å»ºå­å›¾
                fig = make_subplots(
                    rows=len(viz_cols),
                    cols=2,
                    subplot_titles=[f"{col} - åˆ†å¸ƒ" for col in viz_cols] + [f"{col} - ç®±çº¿å›¾" for col in viz_cols],
                    vertical_spacing=0.05
                )

                for i, col in enumerate(viz_cols, 1):
                    if df[col].dtype in ['int64', 'float64']:
                        # ç›´æ–¹å›¾
                        fig.add_trace(
                            go.Histogram(x=df[col], name=col, nbinsx=30),
                            row=i, col=1
                        )
                        # ç®±çº¿å›¾
                        fig.add_trace(
                            go.Box(y=df[col], name=col),
                            row=i, col=2
                        )
                    else:
                        # åˆ†ç±»å˜é‡çš„æ¡å½¢å›¾
                        value_counts = df[col].value_counts().head(20)
                        fig.add_trace(
                            go.Bar(x=value_counts.index, y=value_counts.values, name=col),
                            row=i, col=1
                        )
                        # é¥¼å›¾ï¼ˆåªæ˜¾ç¤ºå‰10ä¸ªç±»åˆ«ï¼‰
                        top_categories = df[col].value_counts().head(10)
                        fig.add_trace(
                            go.Pie(labels=top_categories.index, values=top_categories.values, name=col),
                            row=i, col=2
                        )

                fig.update_layout(height=300 * len(viz_cols), showlegend=False, title_text="æ•°æ®åˆ†å¸ƒåˆ†æ")
                st.plotly_chart(fig, use_container_width=True)

        # 3. ç›¸å…³æ€§åˆ†æ
        if "ğŸ”— ç›¸å…³æ€§åˆ†æ" in explore_options:
            st.markdown('<h3>ğŸ”— ç›¸å…³æ€§åˆ†æ</h3>', unsafe_allow_html=True)

            numeric_df = df.select_dtypes(include=[np.number])
            if len(numeric_df.columns) > 1:
                # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
                corr_matrix = numeric_df.corr()

                # çƒ­åŠ›å›¾
                fig = px.imshow(
                    corr_matrix,
                    text_auto=True,
                    aspect="auto",
                    color_continuous_scale="RdBu",
                    title="ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾"
                )
                st.plotly_chart(fig, use_container_width=True)

                # ç›¸å…³ç³»æ•°è¡¨
                st.write("**ç›¸å…³ç³»æ•°çŸ©é˜µ**:")
                st.dataframe(corr_matrix, use_container_width=True)

                # å¼ºç›¸å…³æ€§ç‰¹å¾å¯¹
                st.write("**å¼ºç›¸å…³æ€§ç‰¹å¾å¯¹ (|r| > 0.7)**:")
                strong_corr = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i + 1, len(corr_matrix.columns)):
                        corr = abs(corr_matrix.iloc[i, j])
                        if corr > 0.7:
                            strong_corr.append({
                                'ç‰¹å¾1': corr_matrix.columns[i],
                                'ç‰¹å¾2': corr_matrix.columns[j],
                                'ç›¸å…³ç³»æ•°': corr_matrix.iloc[i, j]
                            })

                if strong_corr:
                    st.dataframe(pd.DataFrame(strong_corr), use_container_width=True)
                else:
                    st.info("æœªå‘ç°å¼ºç›¸å…³æ€§ç‰¹å¾å¯¹ (|r| > 0.7)")
            else:
                st.warning("æ•°å€¼å‹ç‰¹å¾ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")

        # 4. ç¼ºå¤±å€¼åˆ†æ
        if "ğŸ“‰ ç¼ºå¤±å€¼åˆ†æ" in explore_options:
            st.markdown('<h3>ğŸ“‰ ç¼ºå¤±å€¼åˆ†æ</h3>', unsafe_allow_html=True)

            # ç¼ºå¤±å€¼ç»Ÿè®¡
            missing_stats = pd.DataFrame({
                'åˆ—å': df.columns,
                'ç¼ºå¤±å€¼æ•°é‡': df.isnull().sum().values,
                'ç¼ºå¤±ç‡%': (df.isnull().sum().values / len(df) * 100).round(2)
            }).sort_values('ç¼ºå¤±ç‡%', ascending=False)

            col1, col2 = st.columns(2)

            with col1:
                st.write("**ç¼ºå¤±å€¼ç»Ÿè®¡**:")
                st.dataframe(missing_stats[missing_stats['ç¼ºå¤±å€¼æ•°é‡'] > 0], use_container_width=True)

            with col2:
                # ç¼ºå¤±å€¼çƒ­å›¾
                if df.isnull().sum().sum() > 0:
                    fig = px.imshow(
                        df.isnull(),
                        aspect="auto",
                        labels=dict(x="ç‰¹å¾", y="æ ·æœ¬", color="æ˜¯å¦ç¼ºå¤±"),
                        color_continuous_scale=["white", "red"],
                        title="ç¼ºå¤±å€¼åˆ†å¸ƒçƒ­å›¾"
                    )
                    st.plotly_chart(fig, use_container_width=True)

            # ç¼ºå¤±å€¼æ¨¡å¼åˆ†æ
            st.write("**ç¼ºå¤±å€¼æ¨¡å¼**:")
            missing_pattern = df.isnull().sum(axis=1).value_counts().sort_index()
            fig = px.bar(
                x=missing_pattern.index,
                y=missing_pattern.values,
                labels={'x': 'æ¯è¡Œç¼ºå¤±å€¼æ•°é‡', 'y': 'æ ·æœ¬æ•°'},
                title="æ¯è¡Œç¼ºå¤±å€¼æ•°é‡åˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)

        # 5. ç›®æ ‡å˜é‡åˆ†æ
        if "ğŸ¯ ç›®æ ‡å˜é‡åˆ†æ" in explore_options:
            st.markdown('<h3>ğŸ¯ ç›®æ ‡å˜é‡åˆ†æ</h3>', unsafe_allow_html=True)

            target_col = st.selectbox("é€‰æ‹©ç›®æ ‡å˜é‡", df.columns, key="target_explore")

            if target_col:
                target_series = df[target_col]

                col1, col2 = st.columns(2)

                with col1:
                    # ç›®æ ‡å˜é‡åˆ†å¸ƒ
                    if target_series.dtype in ['int64', 'float64']:
                        # æ•°å€¼å‹ç›®æ ‡å˜é‡
                        fig1 = px.histogram(
                            target_series,
                            nbins=30,
                            title=f"{target_col} åˆ†å¸ƒ",
                            labels={'value': target_col}
                        )
                        st.plotly_chart(fig1, use_container_width=True)

                        # ç»Ÿè®¡ä¿¡æ¯
                        stats = target_series.describe()
                        st.write("**ç»Ÿè®¡æè¿°**:")
                        st.dataframe(pd.DataFrame(stats).T, use_container_width=True)
                    else:
                        # åˆ†ç±»å‹ç›®æ ‡å˜é‡
                        value_counts = target_series.value_counts()
                        fig1 = px.pie(
                            values=value_counts.values,
                            names=value_counts.index,
                            title=f"{target_col} ç±»åˆ«åˆ†å¸ƒ"
                        )
                        st.plotly_chart(fig1, use_container_width=True)

                        st.write("**ç±»åˆ«åˆ†å¸ƒ**:")
                        st.dataframe(value_counts, use_container_width=True)

                with col2:
                    # ç›®æ ‡å˜é‡ä¸å…¶ä»–å˜é‡çš„å…³ç³»
                    if target_series.dtype in ['int64', 'float64']:
                        # å›å½’é—®é¢˜ï¼šç›®æ ‡å˜é‡ä¸æ•°å€¼ç‰¹å¾çš„å…³ç³»
                        numeric_features = df.select_dtypes(include=[np.number]).columns
                        if len(numeric_features) > 1:
                            feature_to_plot = st.selectbox(
                                "é€‰æ‹©ç‰¹å¾æŸ¥çœ‹ä¸ç›®æ ‡å˜é‡çš„å…³ç³»",
                                [col for col in numeric_features if col != target_col]
                            )
                            if feature_to_plot:
                                fig2 = px.scatter(
                                    df,
                                    x=feature_to_plot,
                                    y=target_col,
                                    title=f"{target_col} vs {feature_to_plot}",
                                    trendline="ols"
                                )
                                st.plotly_chart(fig2, use_container_width=True)
                    else:
                        # åˆ†ç±»é—®é¢˜ï¼šç›®æ ‡å˜é‡ä¸æ•°å€¼ç‰¹å¾çš„å…³ç³»
                        numeric_features = df.select_dtypes(include=[np.number]).columns
                        if len(numeric_features) > 0:
                            feature_to_plot = st.selectbox(
                                "é€‰æ‹©ç‰¹å¾æŸ¥çœ‹ä¸ç›®æ ‡å˜é‡çš„å…³ç³»",
                                numeric_features,
                                key="feature_vs_target"
                            )
                            if feature_to_plot:
                                fig2 = px.box(
                                    df,
                                    x=target_col,
                                    y=feature_to_plot,
                                    title=f"{feature_to_plot} åœ¨ä¸åŒ {target_col} ç±»åˆ«ä¸­çš„åˆ†å¸ƒ"
                                )
                                st.plotly_chart(fig2, use_container_width=True)

# ==================== æ•°æ®é¢„å¤„ç† ====================
elif page == "ğŸ§¹ æ•°æ®é¢„å¤„ç†":
    st.markdown('<h2 class="sub-header">ğŸ§¹ æ•°æ®é¢„å¤„ç†</h2>', unsafe_allow_html=True)

    if not st.session_state.datasets:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        st.stop()

    # é€‰æ‹©æ•°æ®é›†
    dataset_names = list(st.session_state.datasets.keys())
    selected_dataset = st.selectbox(
        "é€‰æ‹©è¦é¢„å¤„ç†çš„æ•°æ®é›†",
        dataset_names,
        index=dataset_names.index(st.session_state.current_dataset) if st.session_state.current_dataset else 0
    )

    if selected_dataset:
        df = st.session_state.datasets[selected_dataset]['df'].copy()
        st.session_state.current_dataset = selected_dataset

        # åˆ›å»ºé¢„å¤„ç†é€‰é¡¹æ ‡ç­¾é¡µ
        preprocess_tabs = st.tabs(["ç¼ºå¤±å€¼å¤„ç†", "ç‰¹å¾ç¼–ç ", "ç‰¹å¾ç¼©æ”¾", "ç‰¹å¾é€‰æ‹©", "å¼‚å¸¸å€¼å¤„ç†", "æ•°æ®åˆ†å‰²"])

        # 1. ç¼ºå¤±å€¼å¤„ç†
        with preprocess_tabs[0]:
            st.markdown('<h4>ç¼ºå¤±å€¼å¤„ç†</h4>', unsafe_allow_html=True)

            # æ˜¾ç¤ºç¼ºå¤±å€¼æƒ…å†µ
            missing_cols = df.columns[df.isnull().any()].tolist()
            if missing_cols:
                st.write(f"**å‘ç° {len(missing_cols)} ä¸ªåŒ…å«ç¼ºå¤±å€¼çš„åˆ—**")

                col1, col2 = st.columns(2)
                with col1:
                    st.write("åŒ…å«ç¼ºå¤±å€¼çš„åˆ—:")
                    for col in missing_cols:
                        missing_count = df[col].isnull().sum()
                        missing_pct = missing_count / len(df) * 100
                        st.write(f"- {col}: {missing_count}ä¸ªç¼ºå¤± ({missing_pct:.1f}%)")

                with col2:
                    # ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥
                    st.write("**å¤„ç†ç­–ç•¥**:")
                    strategy = st.radio(
                        "é€‰æ‹©ç¼ºå¤±å€¼å¤„ç†æ–¹æ³•",
                        ["åˆ é™¤ç¼ºå¤±è¡Œ", "æ•°å€¼å‹ï¼šå‡å€¼å¡«å……", "æ•°å€¼å‹ï¼šä¸­ä½æ•°å¡«å……", "åˆ†ç±»å‹ï¼šä¼—æ•°å¡«å……", "å‘å‰å¡«å……",
                         "å‘åå¡«å……"],
                        horizontal=True
                    )

                    # åº”ç”¨å¤„ç†
                    if st.button("åº”ç”¨ç¼ºå¤±å€¼å¤„ç†", key="impute_missing"):
                        df_processed = df.copy()

                        if strategy == "åˆ é™¤ç¼ºå¤±è¡Œ":
                            df_processed = df_processed.dropna()
                            st.success(f"å·²åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œï¼Œå‰©ä½™ {len(df_processed)} è¡Œ")

                        elif "æ•°å€¼å‹" in strategy:
                            numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
                            numeric_cols_with_missing = [col for col in numeric_cols if col in missing_cols]

                            if strategy == "æ•°å€¼å‹ï¼šå‡å€¼å¡«å……":
                                for col in numeric_cols_with_missing:
                                    df_processed[col] = df_processed[col].fillna(df_processed[col].mean())
                            elif strategy == "æ•°å€¼å‹ï¼šä¸­ä½æ•°å¡«å……":
                                for col in numeric_cols_with_missing:
                                    df_processed[col] = df_processed[col].fillna(df_processed[col].median())

                            st.success(f"å·²å¯¹ {len(numeric_cols_with_missing)} ä¸ªæ•°å€¼å‹åˆ—è¿›è¡Œå¡«å……")

                        elif "åˆ†ç±»å‹" in strategy:
                            categorical_cols = df_processed.select_dtypes(include=['object']).columns
                            categorical_cols_with_missing = [col for col in categorical_cols if col in missing_cols]

                            for col in categorical_cols_with_missing:
                                df_processed[col] = df_processed[col].fillna(
                                    df_processed[col].mode()[0] if not df_processed[col].mode().empty else "Unknown")

                            st.success(f"å·²å¯¹ {len(categorical_cols_with_missing)} ä¸ªåˆ†ç±»å‹åˆ—è¿›è¡Œå¡«å……")

                        elif strategy == "å‘å‰å¡«å……":
                            df_processed = df_processed.fillna(method='ffill')
                            st.success("å·²ä½¿ç”¨å‘å‰å¡«å……æ–¹æ³•")

                        elif strategy == "å‘åå¡«å……":
                            df_processed = df_processed.fillna(method='bfill')
                            st.success("å·²ä½¿ç”¨å‘åå¡«å……æ–¹æ³•")

                        # æ›´æ–°æ•°æ®
                        st.session_state.datasets[selected_dataset]['df'] = df_processed
                        st.rerun()
            else:
                st.success("âœ… æ•°æ®ä¸­æ²¡æœ‰ç¼ºå¤±å€¼")

        # 2. ç‰¹å¾ç¼–ç 
        with preprocess_tabs[1]:
            st.markdown('<h4>ç‰¹å¾ç¼–ç </h4>', unsafe_allow_html=True)

            categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
            if categorical_cols:
                st.write(f"**å‘ç° {len(categorical_cols)} ä¸ªåˆ†ç±»å‹ç‰¹å¾**")

                for col in categorical_cols:
                    with st.expander(f"åˆ—: {col}"):
                        unique_vals = df[col].unique()
                        st.write(f"ç±»åˆ«æ•°: {len(unique_vals)}")
                        st.write(
                            f"ç±»åˆ«å€¼: {', '.join(map(str, unique_vals[:10]))}{'...' if len(unique_vals) > 10 else ''}")

                        # ç¼–ç é€‰é¡¹
                        encoding_method = st.radio(
                            f"é€‰æ‹©ç¼–ç æ–¹æ³•",
                            ["æ ‡ç­¾ç¼–ç ", "ç‹¬çƒ­ç¼–ç ", "ä¿ç•™åŸå§‹"],
                            key=f"encode_{col}",
                            horizontal=True
                        )

                        if st.button(f"åº”ç”¨ç¼–ç åˆ° {col}", key=f"apply_encode_{col}"):
                            df_processed = st.session_state.datasets[selected_dataset]['df'].copy()

                            if encoding_method == "æ ‡ç­¾ç¼–ç ":
                                # åˆ›å»ºæˆ–è·å–æ ‡ç­¾ç¼–ç å™¨
                                if col not in st.session_state.label_encoders:
                                    le = LabelEncoder()
                                    st.session_state.label_encoders[col] = le
                                else:
                                    le = st.session_state.label_encoders[col]

                                # è½¬æ¢æ•°æ®
                                df_processed[col] = le.fit_transform(df_processed[col].astype(str))
                                st.success(f"å·²å°† '{col}' è½¬æ¢ä¸ºæ ‡ç­¾ç¼–ç ")

                            elif encoding_method == "ç‹¬çƒ­ç¼–ç ":
                                # ä½¿ç”¨pandasçš„get_dummiesè¿›è¡Œç‹¬çƒ­ç¼–ç 
                                dummies = pd.get_dummies(df_processed[col], prefix=col, drop_first=True)
                                df_processed = pd.concat([df_processed.drop(columns=[col]), dummies], axis=1)
                                st.success(f"å·²å°† '{col}' è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç  ({len(dummies.columns)}ä¸ªæ–°åˆ—)")

                            # æ›´æ–°æ•°æ®
                            st.session_state.datasets[selected_dataset]['df'] = df_processed
                            st.rerun()
            else:
                st.success("âœ… æ•°æ®ä¸­æ²¡æœ‰åˆ†ç±»å‹ç‰¹å¾éœ€è¦ç¼–ç ")

        # 3. ç‰¹å¾ç¼©æ”¾
        with preprocess_tabs[2]:
            st.markdown('<h4>ç‰¹å¾ç¼©æ”¾</h4>', unsafe_allow_html=True)

            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                st.write(f"**å‘ç° {len(numeric_cols)} ä¸ªæ•°å€¼å‹ç‰¹å¾**")

                # é€‰æ‹©ç¼©æ”¾æ–¹æ³•
                scaling_method = st.selectbox(
                    "é€‰æ‹©ç‰¹å¾ç¼©æ”¾æ–¹æ³•",
                    ["æ ‡å‡†åŒ– (StandardScaler)", "å½’ä¸€åŒ– (MinMaxScaler)", "é²æ£’ç¼©æ”¾ (RobustScaler)", "æ— ç¼©æ”¾"]
                )

                # é€‰æ‹©è¦ç¼©æ”¾çš„åˆ—
                cols_to_scale = st.multiselect(
                    "é€‰æ‹©è¦ç¼©æ”¾çš„åˆ—ï¼ˆé»˜è®¤é€‰æ‹©æ‰€æœ‰æ•°å€¼å‹åˆ—ï¼‰",
                    numeric_cols,
                    default=numeric_cols
                )

                if st.button("åº”ç”¨ç‰¹å¾ç¼©æ”¾"):
                    if scaling_method != "æ— ç¼©æ”¾" and cols_to_scale:
                        df_processed = st.session_state.datasets[selected_dataset]['df'].copy()

                        if scaling_method == "æ ‡å‡†åŒ– (StandardScaler)":
                            scaler = StandardScaler()
                        elif scaling_method == "å½’ä¸€åŒ– (MinMaxScaler)":
                            scaler = MinMaxScaler()
                        elif scaling_method == "é²æ£’ç¼©æ”¾ (RobustScaler)":
                            from sklearn.preprocessing import RobustScaler

                            scaler = RobustScaler()

                        # åº”ç”¨ç¼©æ”¾
                        df_processed[cols_to_scale] = scaler.fit_transform(df_processed[cols_to_scale])

                        # ä¿å­˜ç¼©æ”¾å™¨
                        st.session_state.scaler = scaler

                        st.success(f"å·²å¯¹ {len(cols_to_scale)} ä¸ªç‰¹å¾è¿›è¡Œ{scaling_method.split(' ')[0]}")

                        # æ›´æ–°æ•°æ®
                        st.session_state.datasets[selected_dataset]['df'] = df_processed
                        st.rerun()
            else:
                st.info("æ²¡æœ‰æ•°å€¼å‹ç‰¹å¾éœ€è¦ç¼©æ”¾")

        # 4. ç‰¹å¾é€‰æ‹©
        with preprocess_tabs[3]:
            st.markdown('<h4>ç‰¹å¾é€‰æ‹©</h4>', unsafe_allow_html=True)

            st.write("**é€‰æ‹©è¦ä¿ç•™çš„ç‰¹å¾åˆ—**")
            all_cols = list(df.columns)
            selected_features = st.multiselect(
                "é€‰æ‹©ç‰¹å¾ï¼ˆå–æ¶ˆé€‰æ‹©å°†ä»æ•°æ®ä¸­ç§»é™¤ï¼‰",
                all_cols,
                default=all_cols
            )

            # ç›®æ ‡å˜é‡é€‰æ‹©
            target_col = st.selectbox(
                "é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆç”¨äºç‰¹å¾é‡è¦æ€§åˆ†æï¼‰",
                [None] + list(df.columns)
            )

            if target_col and target_col in selected_features:
                # ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆåŸºäºéšæœºæ£®æ—ï¼‰
                from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier

                # å‡†å¤‡æ•°æ®
                X = df[selected_features].drop(columns=[target_col])
                y = df[target_col]

                # å¤„ç†ç¼ºå¤±å€¼
                X = X.fillna(X.mean())

                # åˆ¤æ–­é—®é¢˜ç±»å‹
                if y.dtype == 'object' or y.nunique() < 10:
                    # åˆ†ç±»é—®é¢˜
                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                else:
                    # å›å½’é—®é¢˜
                    model = RandomForestRegressor(n_estimators=100, random_state=42)

                # è®­ç»ƒæ¨¡å‹
                model.fit(X, y)

                # ç‰¹å¾é‡è¦æ€§
                importances = model.feature_importances_
                feature_importance_df = pd.DataFrame({
                    'ç‰¹å¾': X.columns,
                    'é‡è¦æ€§': importances
                }).sort_values('é‡è¦æ€§', ascending=False)

                st.write("**ç‰¹å¾é‡è¦æ€§æ’å**:")
                st.dataframe(feature_importance_df, use_container_width=True)

                # å¯è§†åŒ–
                fig = px.bar(
                    feature_importance_df.head(20),
                    x='é‡è¦æ€§',
                    y='ç‰¹å¾',
                    orientation='h',
                    title='Top 20 ç‰¹å¾é‡è¦æ€§'
                )
                st.plotly_chart(fig, use_container_width=True)

            # åº”ç”¨ç‰¹å¾é€‰æ‹©
            if st.button("åº”ç”¨ç‰¹å¾é€‰æ‹©"):
                if selected_features:
                    df_processed = df[selected_features].copy()
                    st.session_state.datasets[selected_dataset]['df'] = df_processed
                    st.success(f"å·²é€‰æ‹© {len(selected_features)} ä¸ªç‰¹å¾")
                    st.rerun()

        # 5. å¼‚å¸¸å€¼å¤„ç†
        with preprocess_tabs[4]:
            st.markdown('<h4>å¼‚å¸¸å€¼å¤„ç†</h4>', unsafe_allow_html=True)

            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                st.write("**é€‰æ‹©è¦æ£€æµ‹å¼‚å¸¸å€¼çš„åˆ—**")
                outlier_cols = st.multiselect("é€‰æ‹©åˆ—", numeric_cols, default=numeric_cols[:min(3, len(numeric_cols))])

                if outlier_cols:
                    # å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•
                    method = st.radio(
                        "å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•",
                        ["Z-scoreæ³•", "IQRæ³•", "ç™¾åˆ†ä½æ³•"],
                        horizontal=True
                    )

                    threshold = st.slider("å¼‚å¸¸å€¼é˜ˆå€¼", 1.0, 5.0, 3.0, 0.5)

                    if st.button("æ£€æµ‹å¼‚å¸¸å€¼"):
                        df_processed = df.copy()
                        outlier_info = {}

                        for col in outlier_cols:
                            data = df_processed[col].dropna()

                            if method == "Z-scoreæ³•":
                                z_scores = np.abs((data - data.mean()) / data.std())
                                outliers = z_scores > threshold
                                outlier_count = outliers.sum()

                            elif method == "IQRæ³•":
                                Q1 = data.quantile(0.25)
                                Q3 = data.quantile(0.75)
                                IQR = Q3 - Q1
                                lower_bound = Q1 - threshold * IQR
                                upper_bound = Q3 + threshold * IQR
                                outliers = (data < lower_bound) | (data > upper_bound)
                                outlier_count = outliers.sum()

                            elif method == "ç™¾åˆ†ä½æ³•":
                                lower_bound = data.quantile(0.01 * threshold)
                                upper_bound = data.quantile(1 - 0.01 * threshold)
                                outliers = (data < lower_bound) | (data > upper_bound)
                                outlier_count = outliers.sum()

                            outlier_info[col] = {
                                'å¼‚å¸¸å€¼æ•°é‡': outlier_count,
                                'å¼‚å¸¸å€¼æ¯”ä¾‹': outlier_count / len(data) * 100
                            }

                        # æ˜¾ç¤ºå¼‚å¸¸å€¼ä¿¡æ¯
                        outlier_df = pd.DataFrame(outlier_info).T
                        st.write("**å¼‚å¸¸å€¼ç»Ÿè®¡**:")
                        st.dataframe(outlier_df, use_container_width=True)

                        # å¤„ç†é€‰é¡¹
                        treatment = st.radio(
                            "å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•",
                            ["ä¸å¤„ç†", "åˆ é™¤å¼‚å¸¸å€¼", "ç”¨ä¸­ä½æ•°æ›¿æ¢", "ç”¨è¾¹ç•Œå€¼æ›¿æ¢"],
                            horizontal=True
                        )

                        if treatment != "ä¸å¤„ç†" and st.button("åº”ç”¨å¼‚å¸¸å€¼å¤„ç†"):
                            for col in outlier_cols:
                                data = df_processed[col].copy()

                                # é‡æ–°è®¡ç®—å¼‚å¸¸å€¼
                                if method == "Z-scoreæ³•":
                                    z_scores = np.abs((data - data.mean()) / data.std())
                                    outliers = z_scores > threshold
                                elif method == "IQRæ³•":
                                    Q1 = data.quantile(0.25)
                                    Q3 = data.quantile(0.75)
                                    IQR = Q3 - Q1
                                    lower_bound = Q1 - threshold * IQR
                                    upper_bound = Q3 + threshold * IQR
                                    outliers = (data < lower_bound) | (data > upper_bound)
                                elif method == "ç™¾åˆ†ä½æ³•":
                                    lower_bound = data.quantile(0.01 * threshold)
                                    upper_bound = data.quantile(1 - 0.01 * threshold)
                                    outliers = (data < lower_bound) | (data > upper_bound)

                                if treatment == "åˆ é™¤å¼‚å¸¸å€¼":
                                    df_processed = df_processed[~outliers]
                                elif treatment == "ç”¨ä¸­ä½æ•°æ›¿æ¢":
                                    median_val = data.median()
                                    df_processed.loc[outliers, col] = median_val
                                elif treatment == "ç”¨è¾¹ç•Œå€¼æ›¿æ¢":
                                    if method == "IQRæ³•":
                                        Q1 = data.quantile(0.25)
                                        Q3 = data.quantile(0.75)
                                        IQR = Q3 - Q1
                                        lower_bound = Q1 - threshold * IQR
                                        upper_bound = Q3 + threshold * IQR
                                    elif method == "ç™¾åˆ†ä½æ³•":
                                        lower_bound = data.quantile(0.01 * threshold)
                                        upper_bound = data.quantile(1 - 0.01 * threshold)
                                    else:  # Z-scoreæ³•
                                        mean_val = data.mean()
                                        std_val = data.std()
                                        lower_bound = mean_val - threshold * std_val
                                        upper_bound = mean_val + threshold * std_val

                                    df_processed.loc[outliers & (data < lower_bound), col] = lower_bound
                                    df_processed.loc[outliers & (data > upper_bound), col] = upper_bound

                            st.session_state.datasets[selected_dataset]['df'] = df_processed
                            st.success(f"å¼‚å¸¸å€¼å¤„ç†å®Œæˆï¼Œå‰©ä½™ {len(df_processed)} è¡Œæ•°æ®")
                            st.rerun()
            else:
                st.info("æ²¡æœ‰æ•°å€¼å‹ç‰¹å¾è¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹")

        # 6. æ•°æ®åˆ†å‰²
        with preprocess_tabs[5]:
            st.markdown('<h4>æ•°æ®åˆ†å‰²</h4>', unsafe_allow_html=True)

            # ç›®æ ‡å˜é‡é€‰æ‹©
            target_options = [None] + list(df.columns)
            target_col = st.selectbox("é€‰æ‹©ç›®æ ‡å˜é‡", target_options, key="split_target")

            if target_col:
                # åˆ†å‰²å‚æ•°
                col1, col2, col3 = st.columns(3)
                with col1:
                    test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
                with col2:
                    random_state = st.number_input("éšæœºç§å­", 0, 100, 42)
                with col3:
                    shuffle = st.checkbox("æ‰“ä¹±æ•°æ®", True)

                # ä¿å­˜åˆ†å‰²å‚æ•°åˆ°session state
                st.session_state.split_params = {
                    'target_col': target_col,
                    'test_size': test_size,
                    'random_state': random_state,
                    'shuffle': shuffle
                }

                st.success(f"âœ… å·²è®¾ç½®ç›®æ ‡å˜é‡: {target_col}")
                st.info(f"å°†æŒ‰ç…§ {1 - test_size:.0%}/{test_size:.0%} çš„æ¯”ä¾‹åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†")

# ==================== æ¨¡å‹è®­ç»ƒ ====================
elif page == "ğŸ¤– æ¨¡å‹è®­ç»ƒ":
    st.markdown('<h2 class="sub-header">ğŸ¤– æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ</h2>', unsafe_allow_html=True)

    if not st.session_state.datasets:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶é¢„å¤„ç†æ•°æ®")
        st.stop()

    # é€‰æ‹©æ•°æ®é›†
    dataset_names = list(st.session_state.datasets.keys())
    selected_dataset = st.selectbox(
        "é€‰æ‹©è¦å»ºæ¨¡çš„æ•°æ®é›†",
        dataset_names,
        index=dataset_names.index(st.session_state.current_dataset) if st.session_state.current_dataset else 0
    )

    if selected_dataset:
        df = st.session_state.datasets[selected_dataset]['df']

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†å‰²å‚æ•°
        if 'split_params' not in st.session_state:
            st.warning("âš ï¸ è¯·å…ˆåœ¨'æ•°æ®é¢„å¤„ç†'é¡µé¢è®¾ç½®æ•°æ®åˆ†å‰²å‚æ•°")
            st.stop()

        split_params = st.session_state.split_params
        target_col = split_params['target_col']

        if target_col not in df.columns:
            st.error(f"âŒ ç›®æ ‡å˜é‡ '{target_col}' ä¸åœ¨æ•°æ®é›†ä¸­")
            st.stop()

        # å‡†å¤‡æ•°æ®
        X = df.drop(columns=[target_col])
        y = df[target_col]

        # åˆ¤æ–­é—®é¢˜ç±»å‹
        if y.dtype == 'object' or y.nunique() < 10:
            problem_type = 'classification'
            st.info(f"ğŸ” æ£€æµ‹åˆ°åˆ†ç±»é—®é¢˜ï¼Œç›®æ ‡å˜é‡æœ‰ {y.nunique()} ä¸ªç±»åˆ«")
        else:
            problem_type = 'regression'
            st.info(f"ğŸ” æ£€æµ‹åˆ°å›å½’é—®é¢˜ï¼Œç›®æ ‡å˜é‡ä¸ºè¿ç»­æ•°å€¼")

        # æ¨¡å‹é€‰æ‹©
        st.markdown('<h4>é€‰æ‹©æœºå™¨å­¦ä¹ æ¨¡å‹</h4>', unsafe_allow_html=True)

        # æ ¹æ®é—®é¢˜ç±»å‹æ˜¾ç¤ºä¸åŒçš„æ¨¡å‹é€‰é¡¹
        if problem_type == 'classification':
            models = {
                "éšæœºæ£®æ—": RandomForestClassifier,
                "æ¢¯åº¦æå‡": GradientBoostingClassifier,
                "é€»è¾‘å›å½’": LogisticRegression,
                "æ”¯æŒå‘é‡æœº": SVC,
                "Kè¿‘é‚»": KNeighborsClassifier,
                "å†³ç­–æ ‘": DecisionTreeClassifier,
                "ç¥ç»ç½‘ç»œ": MLPClassifier,
                "XGBoost": xgb.XGBClassifier,
                "LightGBM": lgb.LGBMClassifier,
                "AdaBoost": AdaBoostClassifier,
                "æœ´ç´ è´å¶æ–¯": GaussianNB
            }
        else:
            models = {
                "éšæœºæ£®æ—": RandomForestRegressor,
                "æ¢¯åº¦æå‡": GradientBoostingRegressor,
                "çº¿æ€§å›å½’": LinearRegression,
                "æ”¯æŒå‘é‡å›å½’": SVR,
                "Kè¿‘é‚»å›å½’": KNeighborsRegressor,
                "å†³ç­–æ ‘å›å½’": DecisionTreeRegressor,
                "ç¥ç»ç½‘ç»œå›å½’": MLPRegressor,
                "XGBoostå›å½’": xgb.XGBRegressor,
                "LightGBMå›å½’": lgb.LGBMRegressor,
                "AdaBoostå›å½’": AdaBoostRegressor,
                "å²­å›å½’": Ridge,
                "Lassoå›å½’": Lasso
            }

        # æ¨¡å‹é€‰æ‹©
        selected_model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", list(models.keys()))

        # æ˜¾ç¤ºæ¨¡å‹æè¿°
        model_descriptions = {
            "éšæœºæ£®æ—": "é›†æˆå­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡å¤šä¸ªå†³ç­–æ ‘æŠ•ç¥¨ï¼ŒæŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›å¼º",
            "æ¢¯åº¦æå‡": "é€æ­¥ä¼˜åŒ–æ¨¡å‹ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™å‡å°‘æ®‹å·®",
            "é€»è¾‘å›å½’/çº¿æ€§å›å½’": "çº¿æ€§æ¨¡å‹ï¼Œé€‚åˆçº¿æ€§å¯åˆ†æ•°æ®ï¼Œè§£é‡Šæ€§å¼º",
            "æ”¯æŒå‘é‡æœº": "é€šè¿‡å¯»æ‰¾æœ€å¤§é—´éš”è¶…å¹³é¢è¿›è¡Œåˆ†ç±»ï¼Œé€‚åˆé«˜ç»´æ•°æ®",
            "Kè¿‘é‚»": "åŸºäºç›¸ä¼¼æ€§åº¦é‡ï¼Œç®€å•ç›´è§‚",
            "å†³ç­–æ ‘": "æ ‘å½¢ç»“æ„ï¼Œå¯è§£é‡Šæ€§å¼º",
            "ç¥ç»ç½‘ç»œ": "æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€‚åˆå¤æ‚éçº¿æ€§å…³ç³»",
            "XGBoost": "ä¼˜åŒ–çš„æ¢¯åº¦æå‡ç®—æ³•ï¼Œæ€§èƒ½ä¼˜å¼‚",
            "LightGBM": "åŸºäºç›´æ–¹å›¾çš„æ¢¯åº¦æå‡ï¼Œè®­ç»ƒé€Ÿåº¦å¿«",
            "AdaBoost": "è‡ªé€‚åº”æå‡ç®—æ³•ï¼Œå…³æ³¨å›°éš¾æ ·æœ¬",
            "æœ´ç´ è´å¶æ–¯": "åŸºäºè´å¶æ–¯å®šç†ï¼Œé€‚åˆæ–‡æœ¬åˆ†ç±»",
            "å²­å›å½’": "çº¿æ€§å›å½’+L2æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ",
            "Lassoå›å½’": "çº¿æ€§å›å½’+L1æ­£åˆ™åŒ–ï¼Œå¯è¿›è¡Œç‰¹å¾é€‰æ‹©"
        }

        st.info(f"**{selected_model_name}**: {model_descriptions.get(selected_model_name, '')}")

        # è¶…å‚æ•°è°ƒèŠ‚
        st.markdown('<h4>è¶…å‚æ•°è°ƒèŠ‚</h4>', unsafe_allow_html=True)

        # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ˜¾ç¤ºç›¸åº”çš„è¶…å‚æ•°
        params = {}

        if selected_model_name in ["éšæœºæ£®æ—", "æ¢¯åº¦æå‡", "å†³ç­–æ ‘"]:
            col1, col2, col3 = st.columns(3)
            with col1:
                params['n_estimators'] = st.slider("æ ‘çš„æ•°é‡", 10, 500, 100,
                                                   10) if selected_model_name != "å†³ç­–æ ‘" else 1
            with col2:
                params['max_depth'] = st.slider("æœ€å¤§æ·±åº¦", 1, 20, 10)
            with col3:
                params['random_state'] = st.number_input("éšæœºç§å­", 0, 100, 42)

        elif selected_model_name == "ç¥ç»ç½‘ç»œ":
            col1, col2 = st.columns(2)
            with col1:
                hidden_layers = st.text_input("éšè—å±‚ç»“æ„", "100,50",
                                              help="ä¾‹å¦‚: 100,50 è¡¨ç¤ºä¸¤ä¸ªéšè—å±‚ï¼Œåˆ†åˆ«æœ‰100å’Œ50ä¸ªç¥ç»å…ƒ")
                params['hidden_layer_sizes'] = tuple(map(int, hidden_layers.split(','))) if hidden_layers else (100,)
            with col2:
                params['max_iter'] = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 5000, 1000, 100)
                params['random_state'] = st.number_input("éšæœºç§å­", 0, 100, 42)

        elif selected_model_name in ["XGBoost", "LightGBM"]:
            col1, col2, col3 = st.columns(3)
            with col1:
                params['n_estimators'] = st.slider("æ ‘çš„æ•°é‡", 10, 500, 100, 10)
            with col2:
                params['max_depth'] = st.slider("æœ€å¤§æ·±åº¦", 1, 20, 6)
            with col3:
                params['learning_rate'] = st.slider("å­¦ä¹ ç‡", 0.01, 0.5, 0.1, 0.01)

        elif selected_model_name == "æ”¯æŒå‘é‡æœº":
            col1, col2 = st.columns(2)
            with col1:
                params['C'] = st.slider("æ­£åˆ™åŒ–å‚æ•°C", 0.1, 10.0, 1.0, 0.1)
            with col2:
                params['kernel'] = st.selectbox("æ ¸å‡½æ•°", ["rbf", "linear", "poly", "sigmoid"])

        elif selected_model_name == "Kè¿‘é‚»":
            params['n_neighbors'] = st.slider("é‚»å±…æ•°é‡", 1, 20, 5)

        # è®­ç»ƒé€‰é¡¹
        st.markdown('<h4>è®­ç»ƒé€‰é¡¹</h4>', unsafe_allow_html=True)

        col1, col2, col3 = st.columns(3)
        with col1:
            use_cross_val = st.checkbox("ä½¿ç”¨äº¤å‰éªŒè¯", True)
        with col2:
            if use_cross_val:
                cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 10, 5)
        with col3:
            verbose = st.checkbox("æ˜¾ç¤ºè®­ç»ƒè¯¦æƒ…", False)

        # å¼€å§‹è®­ç»ƒæŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹", use_container_width=True):
            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                try:
                    # åˆ›å»ºæ¨¡å‹å®ä¾‹
                    model_class = models[selected_model_name]

                    # å¤„ç†ç‰¹æ®Šå‚æ•°
                    model_params = {}
                    for key, value in params.items():
                        if key == 'hidden_layer_sizes' and isinstance(value, str):
                            model_params[key] = tuple(map(int, value.split(',')))
                        else:
                            model_params[key] = value

                    # åˆ›å»ºæ¨¡å‹
                    model = model_class(**model_params)

                    # æ•°æ®åˆ†å‰²
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y,
                        test_size=split_params['test_size'],
                        random_state=split_params['random_state'],
                        shuffle=split_params['shuffle'],
                        stratify=y if problem_type == 'classification' else None
                    )

                    # ç‰¹å¾ç¼©æ”¾
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)

                    # ä¿å­˜ç¼©æ”¾å™¨
                    st.session_state.scaler = scaler

                    # è®­ç»ƒæ¨¡å‹
                    if use_cross_val:
                        # äº¤å‰éªŒè¯
                        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv_folds,
                                                    scoring='accuracy' if problem_type == 'classification' else 'r2')

                        # æ˜¾ç¤ºäº¤å‰éªŒè¯ç»“æœ
                        st.success(f"âœ… äº¤å‰éªŒè¯å®Œæˆ ({cv_folds}æŠ˜)")
                        st.write(f"äº¤å‰éªŒè¯å¾—åˆ†: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")

                        # å¯è§†åŒ–äº¤å‰éªŒè¯ç»“æœ
                        fig = go.Figure(data=[
                            go.Bar(
                                x=[f'Fold {i + 1}' for i in range(cv_folds)],
                                y=cv_scores,
                                text=[f'{score:.4f}' for score in cv_scores],
                                textposition='auto',
                            )
                        ])
                        fig.update_layout(
                            title=f"{selected_model_name} äº¤å‰éªŒè¯ç»“æœ",
                            yaxis_title="å¾—åˆ†",
                            xaxis_title="æŠ˜å ",
                            showlegend=False
                        )
                        st.plotly_chart(fig, use_container_width=True)

                    # æœ€ç»ˆè®­ç»ƒ
                    model.fit(X_train_scaled, y_train)

                    # ä¿å­˜æ¨¡å‹åˆ°session state
                    st.session_state.model = model
                    st.session_state.X_test = X_test_scaled
                    st.session_state.y_test = y_test
                    st.session_state.X_train = X_train_scaled
                    st.session_state.y_train = y_train
                    st.session_state.feature_names = list(X.columns)
                    st.session_state.problem_type = problem_type
                    st.session_state.model_name = selected_model_name

                    st.success(f"âœ… {selected_model_name} æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

                    # æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("è®­ç»ƒé›†å¤§å°", len(X_train))
                    with col2:
                        st.metric("æµ‹è¯•é›†å¤§å°", len(X_test))
                    with col3:
                        st.metric("ç‰¹å¾æ•°é‡", X_train.shape[1])

                except Exception as e:
                    st.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")

# ==================== æ¨¡å‹è¯„ä¼° ====================
elif page == "ğŸ“Š æ¨¡å‹è¯„ä¼°":
    st.markdown('<h2 class="sub-header">ğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°</h2>', unsafe_allow_html=True)

    if st.session_state.model is None:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        st.stop()

    model = st.session_state.model
    X_test = st.session_state.X_test
    y_test = st.session_state.y_test
    problem_type = st.session_state.problem_type

    # é¢„æµ‹
    y_pred = model.predict(X_test)

    # è¯„ä¼°æŒ‡æ ‡
    st.markdown('<h4>æ¨¡å‹æ€§èƒ½æŒ‡æ ‡</h4>', unsafe_allow_html=True)

    if problem_type == 'classification':
        # åˆ†ç±»æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')

        # æ˜¾ç¤ºæŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å‡†ç¡®ç‡", f"{accuracy:.4f}")
        with col2:
            st.metric("ç²¾ç¡®ç‡", f"{precision:.4f}")
        with col3:
            st.metric("å¬å›ç‡", f"{recall:.4f}")
        with col4:
            st.metric("F1åˆ†æ•°", f"{f1:.4f}")

        # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        st.write("**è¯¦ç»†åˆ†ç±»æŠ¥å‘Š**:")
        report = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df, use_container_width=True)

        # æ··æ·†çŸ©é˜µ
        st.write("**æ··æ·†çŸ©é˜µ**:")
        cm = confusion_matrix(y_test, y_pred)

        fig = px.imshow(
            cm,
            text_auto=True,
            color_continuous_scale='Blues',
            labels=dict(x="é¢„æµ‹æ ‡ç­¾", y="çœŸå®æ ‡ç­¾", color="æ•°é‡"),
            title="æ··æ·†çŸ©é˜µ"
        )
        st.plotly_chart(fig, use_container_width=True)

        # ROCæ›²çº¿ï¼ˆå¦‚æœæ˜¯äºŒåˆ†ç±»ï¼‰
        if len(np.unique(y_test)) == 2 and hasattr(model, 'predict_proba'):
            y_prob = model.predict_proba(X_test)[:, 1]
            fpr, tpr, _ = roc_curve(y_test, y_prob)
            roc_auc = auc(fpr, tpr)

            fig_roc = go.Figure()
            fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROCæ›²çº¿ (AUC = {roc_auc:.2f})'))
            fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='éšæœºåˆ†ç±»å™¨', line=dict(dash='dash')))
            fig_roc.update_layout(
                title='ROCæ›²çº¿',
                xaxis_title='å‡é˜³æ€§ç‡',
                yaxis_title='çœŸé˜³æ€§ç‡',
                showlegend=True
            )
            st.plotly_chart(fig_roc, use_container_width=True)

    else:
        # å›å½’æŒ‡æ ‡
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        # æ˜¾ç¤ºæŒ‡æ ‡
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å‡æ–¹è¯¯å·® (MSE)", f"{mse:.4f}")
        with col2:
            st.metric("å¹³å‡ç»å¯¹è¯¯å·® (MAE)", f"{mae:.4f}")
        with col3:
            st.metric("RÂ²åˆ†æ•°", f"{r2:.4f}")

        # é¢„æµ‹ vs çœŸå®å€¼å›¾
        st.write("**é¢„æµ‹ç»“æœ vs çœŸå®å€¼**:")

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=y_test, y=y_pred, mode='markers',
            marker=dict(size=10, opacity=0.6),
            name='é¢„æµ‹ç‚¹'
        ))
        fig.add_trace(go.Scatter(
            x=[y_test.min(), y_test.max()],
            y=[y_test.min(), y_test.max()],
            mode='lines',
            line=dict(color='red', dash='dash'),
            name='å®Œç¾é¢„æµ‹çº¿'
        ))
        fig.update_layout(
            title='é¢„æµ‹å€¼ vs çœŸå®å€¼',
            xaxis_title='çœŸå®å€¼',
            yaxis_title='é¢„æµ‹å€¼',
            showlegend=True
        )
        st.plotly_chart(fig, use_container_width=True)

        # æ®‹å·®å›¾
        st.write("**æ®‹å·®åˆ†æ**:")
        residuals = y_test - y_pred

        fig_res = make_subplots(
            rows=1, cols=2,
            subplot_titles=('æ®‹å·®åˆ†å¸ƒ', 'æ®‹å·® vs é¢„æµ‹å€¼')
        )

        fig_res.add_trace(
            go.Histogram(x=residuals, nbinsx=30, name='æ®‹å·®åˆ†å¸ƒ'),
            row=1, col=1
        )
        fig_res.add_trace(
            go.Scatter(x=y_pred, y=residuals, mode='markers', name='æ®‹å·®'),
            row=1, col=2
        )
        fig_res.add_hline(y=0, line_dash="dash", line_color="red", row=1, col=2)

        fig_res.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig_res, use_container_width=True)

    # ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if hasattr(model, 'feature_importances_'):
        st.markdown('<h4>ç‰¹å¾é‡è¦æ€§</h4>', unsafe_allow_html=True)

        importances = model.feature_importances_
        feature_names = st.session_state.feature_names

        importance_df = pd.DataFrame({
            'ç‰¹å¾': feature_names,
            'é‡è¦æ€§': importances
        }).sort_values('é‡è¦æ€§', ascending=False)

        # æ˜¾ç¤ºè¡¨æ ¼
        st.dataframe(importance_df, use_container_width=True)

        # å¯è§†åŒ–
        fig = px.bar(
            importance_df.head(20),
            x='é‡è¦æ€§',
            y='ç‰¹å¾',
            orientation='h',
            title='Top 20 ç‰¹å¾é‡è¦æ€§',
            color='é‡è¦æ€§',
            color_continuous_scale='Viridis'
        )
        st.plotly_chart(fig, use_container_width=True)

# ==================== äº¤äº’å¼é¢„æµ‹ ====================
elif page == "ğŸ”® äº¤äº’å¼é¢„æµ‹":
    st.markdown('<h2 class="sub-header">ğŸ”® äº¤äº’å¼é¢„æµ‹</h2>', unsafe_allow_html=True)

    if st.session_state.model is None:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        st.stop()

    model = st.session_state.model
    scaler = st.session_state.scaler
    feature_names = st.session_state.feature_names
    problem_type = st.session_state.problem_type

    st.info(f"å½“å‰ä½¿ç”¨æ¨¡å‹: **{st.session_state.model_name}** | é—®é¢˜ç±»å‹: **{problem_type}**")

    # åˆ›å»ºé¢„æµ‹æ ‡ç­¾é¡µ
    predict_tabs = st.tabs(["æ‰‹åŠ¨è¾“å…¥", "æ‰¹é‡é¢„æµ‹", "å‚æ•°æ¢ç´¢"])

    # 1. æ‰‹åŠ¨è¾“å…¥é¢„æµ‹
    with predict_tabs[0]:
        st.write("### æ‰‹åŠ¨è¾“å…¥ç‰¹å¾å€¼è¿›è¡Œé¢„æµ‹")

        # åŠ¨æ€åˆ›å»ºè¾“å…¥æ¡†
        input_values = {}
        cols = st.columns(3)  # æ¯è¡Œ3åˆ—

        for i, feature in enumerate(feature_names):
            with cols[i % 3]:
                # è·å–è¯¥ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯ç”¨äºæŒ‡å¯¼è¾“å…¥
                if hasattr(st.session_state, 'X_train'):
                    # ä»è®­ç»ƒæ•°æ®ä¸­è·å–ç»Ÿè®¡ä¿¡æ¯
                    train_data = st.session_state.X_train[:, i]
                    mean_val = train_data.mean()
                    std_val = train_data.std()
                    min_val = train_data.min()
                    max_val = train_data.max()

                    # åˆ›å»ºè¾“å…¥æ¡†
                    input_values[feature] = st.slider(
                        f"{feature}",
                        float(min_val - 2 * std_val),
                        float(max_val + 2 * std_val),
                        float(mean_val),
                        help=f"èŒƒå›´: [{min_val:.2f}, {max_val:.2f}]"
                    )
                else:
                    # å¦‚æœæ²¡æœ‰è®­ç»ƒæ•°æ®ä¿¡æ¯ï¼Œä½¿ç”¨é€šç”¨èŒƒå›´
                    input_values[feature] = st.number_input(f"{feature}", value=0.0)

        # é¢„æµ‹æŒ‰é’®
        if st.button("è¿›è¡Œé¢„æµ‹", key="manual_predict"):
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_array = np.array([input_values[feature] for feature in feature_names]).reshape(1, -1)

            # ç‰¹å¾ç¼©æ”¾
            if scaler is not None:
                input_scaled = scaler.transform(input_array)
            else:
                input_scaled = input_array

            # è¿›è¡Œé¢„æµ‹
            prediction = model.predict(input_scaled)[0]

            # æ˜¾ç¤ºç»“æœ
            st.markdown('<div class="success-box">', unsafe_allow_html=True)
            st.write(f"### ğŸ“Š é¢„æµ‹ç»“æœ")

            if problem_type == 'classification':
                if hasattr(model, 'predict_proba'):
                    probabilities = model.predict_proba(input_scaled)[0]
                    st.write(f"**é¢„æµ‹ç±»åˆ«**: {prediction}")
                    st.write(f"**å„ç±»åˆ«æ¦‚ç‡**:")

                    # æ˜¾ç¤ºæ¦‚ç‡æ¡å½¢å›¾
                    prob_df = pd.DataFrame({
                        'ç±»åˆ«': [str(i) for i in range(len(probabilities))],
                        'æ¦‚ç‡': probabilities
                    })

                    fig = px.bar(
                        prob_df,
                        x='ç±»åˆ«',
                        y='æ¦‚ç‡',
                        title='ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ',
                        color='æ¦‚ç‡',
                        color_continuous_scale='Viridis'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.write(f"**é¢„æµ‹ç»“æœ**: {prediction}")
            else:
                st.write(f"**é¢„æµ‹å€¼**: {prediction:.4f}")

            st.markdown('</div>', unsafe_allow_html=True)

    # 2. æ‰¹é‡é¢„æµ‹
    with predict_tabs[1]:
        st.write("### æ‰¹é‡é¢„æµ‹ï¼ˆä¸Šä¼ æ–°æ•°æ®æ–‡ä»¶ï¼‰")

        uploaded_pred_file = st.file_uploader(
            "ä¸Šä¼ åŒ…å«ç‰¹å¾æ•°æ®çš„Excelæˆ–CSVæ–‡ä»¶",
            type=['xlsx', 'xls', 'csv'],
            key="prediction_file"
        )

        if uploaded_pred_file:
            try:
                # è¯»å–æ–‡ä»¶
                if uploaded_pred_file.name.endswith('.csv'):
                    new_data = pd.read_csv(uploaded_pred_file)
                else:
                    new_data = pd.read_excel(uploaded_pred_file)

                st.success(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œæ•°æ®å½¢çŠ¶: {new_data.shape}")

                # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åŒ¹é…
                missing_features = [f for f in feature_names if f not in new_data.columns]
                extra_features = [f for f in new_data.columns if f not in feature_names]

                if missing_features:
                    st.warning(f"âš ï¸ æ•°æ®ä¸­ç¼ºå°‘ä»¥ä¸‹ç‰¹å¾: {missing_features}")

                if extra_features:
                    st.info(f"â„¹ï¸ æ•°æ®ä¸­åŒ…å«é¢å¤–ç‰¹å¾: {extra_features}")

                # é€‰æ‹©è¦ä½¿ç”¨çš„ç‰¹å¾
                if missing_features:
                    st.warning("æ— æ³•è¿›è¡Œé¢„æµ‹ï¼Œç‰¹å¾ä¸åŒ¹é…")
                else:
                    # æå–ç‰¹å¾æ•°æ®
                    X_new = new_data[feature_names]

                    # å¤„ç†ç¼ºå¤±å€¼
                    if X_new.isnull().any().any():
                        st.warning("âš ï¸ æ•°æ®ä¸­å­˜åœ¨ç¼ºå¤±å€¼ï¼Œå°†ä½¿ç”¨ä¸­ä½æ•°å¡«å……")
                        X_new = X_new.fillna(X_new.median())

                    # ç‰¹å¾ç¼©æ”¾
                    if scaler is not None:
                        X_new_scaled = scaler.transform(X_new)
                    else:
                        X_new_scaled = X_new.values

                    # æ‰¹é‡é¢„æµ‹
                    if st.button("å¼€å§‹æ‰¹é‡é¢„æµ‹", key="batch_predict"):
                        with st.spinner("æ­£åœ¨æ‰¹é‡é¢„æµ‹..."):
                            predictions = model.predict(X_new_scaled)

                            # å¦‚æœæ˜¯åˆ†ç±»ä¸”æœ‰æ¦‚ç‡é¢„æµ‹
                            if problem_type == 'classification' and hasattr(model, 'predict_proba'):
                                probabilities = model.predict_proba(X_new_scaled)

                                # åˆ›å»ºç»“æœDataFrame
                                result_df = new_data.copy()
                                result_df['é¢„æµ‹ç±»åˆ«'] = predictions

                                # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡
                                for i in range(probabilities.shape[1]):
                                    result_df[f'ç±»åˆ«_{i}_æ¦‚ç‡'] = probabilities[:, i]

                            else:
                                result_df = new_data.copy()
                                result_df['é¢„æµ‹å€¼'] = predictions

                            # æ˜¾ç¤ºç»“æœ
                            st.success(f"âœ… é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} æ¡è®°å½•")

                            # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                            st.write("**é¢„æµ‹ç»“æœé¢„è§ˆ**:")
                            st.dataframe(result_df.head(), use_container_width=True)

                            # ç»Ÿè®¡ä¿¡æ¯
                            if problem_type == 'classification':
                                prediction_counts = pd.Series(predictions).value_counts()
                                st.write("**é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ**:")
                                st.dataframe(prediction_counts, use_container_width=True)

                                # å¯è§†åŒ–åˆ†å¸ƒ
                                fig = px.pie(
                                    values=prediction_counts.values,
                                    names=prediction_counts.index,
                                    title='é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ'
                                )
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                st.write("**é¢„æµ‹å€¼ç»Ÿè®¡**:")
                                st.dataframe(pd.Series(predictions).describe(), use_container_width=True)

                            # ä¸‹è½½ç»“æœ
                            csv = result_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ (CSV)",
                                data=csv,
                                file_name="é¢„æµ‹ç»“æœ.csv",
                                mime="text/csv",
                            )

            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

    # 3. å‚æ•°æ¢ç´¢
    with predict_tabs[2]:
        st.write("### å‚æ•°æ¢ç´¢ä¸å½±å“åˆ†æ")

        if len(feature_names) >= 2:
            # é€‰æ‹©è¦æ¢ç´¢çš„ç‰¹å¾
            col1, col2 = st.columns(2)
            with col1:
                feature_x = st.selectbox("é€‰æ‹©Xè½´ç‰¹å¾", feature_names, index=0)
            with col2:
                feature_y = st.selectbox("é€‰æ‹©Yè½´ç‰¹å¾", feature_names, index=1 if len(feature_names) > 1 else 0)

            # åˆ›å»ºç½‘æ ¼
            x_range = st.slider(f"{feature_x} èŒƒå›´", -3.0, 3.0, (-2.0, 2.0), 0.1)
            y_range = st.slider(f"{feature_y} èŒƒå›´", -3.0, 3.0, (-2.0, 2.0), 0.1)
            grid_size = st.slider("ç½‘æ ¼å¤§å°", 10, 100, 50)

            if st.button("ç”Ÿæˆé¢„æµ‹çƒ­å›¾", key="heatmap_predict"):
                # åˆ›å»ºç½‘æ ¼
                x_values = np.linspace(x_range[0], x_range[1], grid_size)
                y_values = np.linspace(y_range[0], y_range[1], grid_size)
                xx, yy = np.meshgrid(x_values, y_values)

                # åˆ›å»ºåŸºç¡€ç‰¹å¾çŸ©é˜µï¼ˆæ‰€æœ‰ç‰¹å¾å–å¹³å‡å€¼ï¼‰
                base_values = np.zeros((grid_size * grid_size, len(feature_names)))

                # è·å–å…¶ä»–ç‰¹å¾çš„å¹³å‡å€¼
                if hasattr(st.session_state, 'X_train'):
                    other_feature_means = st.session_state.X_train.mean(axis=0)
                else:
                    other_feature_means = np.zeros(len(feature_names))

                # å¡«å……åŸºç¡€å€¼
                for i, feature in enumerate(feature_names):
                    base_values[:, i] = other_feature_means[i]

                # è®¾ç½®é€‰å®šç‰¹å¾çš„å€¼
                x_idx = feature_names.index(feature_x)
                y_idx = feature_names.index(feature_y)

                base_values[:, x_idx] = xx.ravel()
                base_values[:, y_idx] = yy.ravel()

                # è¿›è¡Œé¢„æµ‹
                predictions = model.predict(base_values)

                # é‡å¡‘é¢„æµ‹ç»“æœ
                if problem_type == 'classification':
                    zz = predictions.reshape(xx.shape)
                else:
                    zz = predictions.reshape(xx.shape)

                # åˆ›å»ºçƒ­å›¾
                fig = go.Figure(data=[
                    go.Contour(
                        x=x_values,
                        y=y_values,
                        z=zz,
                        colorscale='Viridis',
                        contours=dict(
                            showlabels=True,
                            labelfont=dict(size=12, color='white')
                        )
                    )
                ])

                fig.update_layout(
                    title=f"é¢„æµ‹çƒ­å›¾: {feature_x} vs {feature_y}",
                    xaxis_title=feature_x,
                    yaxis_title=feature_y,
                    height=500
                )

                st.plotly_chart(fig, use_container_width=True)

                # æ·»åŠ æ•£ç‚¹å›¾æ˜¾ç¤ºè®­ç»ƒæ•°æ®ç‚¹
                if hasattr(st.session_state, 'X_train'):
                    train_data = st.session_state.X_train

                    # è·å–é€‰å®šç‰¹å¾çš„è®­ç»ƒæ•°æ®
                    x_train = train_data[:, x_idx]
                    y_train = train_data[:, y_idx]

                    fig.add_trace(go.Scatter(
                        x=x_train,
                        y=y_train,
                        mode='markers',
                        marker=dict(
                            size=8,
                            color='red',
                            symbol='circle',
                            opacity=0.6
                        ),
                        name='è®­ç»ƒæ•°æ®ç‚¹'
                    ))

                    st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("éœ€è¦è‡³å°‘2ä¸ªç‰¹å¾æ‰èƒ½è¿›è¡Œå‚æ•°æ¢ç´¢")

# ==================== æ¨¡å‹ç®¡ç† ====================
elif page == "ğŸ’¾ æ¨¡å‹ç®¡ç†":
    st.markdown('<h2 class="sub-header">ğŸ’¾ æ¨¡å‹ç®¡ç†</h2>', unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown('<h4>ä¿å­˜å½“å‰æ¨¡å‹</h4>', unsafe_allow_html=True)

        if st.session_state.model is not None:
            model_name = st.text_input("æ¨¡å‹åç§°", "bio_model")
            include_scaler = st.checkbox("åŒ…å«ç‰¹å¾ç¼©æ”¾å™¨", True)
            include_encoders = st.checkbox("åŒ…å«æ ‡ç­¾ç¼–ç å™¨", True)

            if st.button("ğŸ’¾ ä¿å­˜æ¨¡å‹"):
                try:
                    # å‡†å¤‡ä¿å­˜çš„æ•°æ®
                    save_data = {
                        'model': st.session_state.model,
                        'model_name': st.session_state.model_name,
                        'problem_type': st.session_state.problem_type,
                        'feature_names': st.session_state.feature_names,
                        'timestamp': pd.Timestamp.now()
                    }

                    if include_scaler and st.session_state.scaler is not None:
                        save_data['scaler'] = st.session_state.scaler

                    if include_encoders and st.session_state.label_encoders:
                        save_data['label_encoders'] = st.session_state.label_encoders

                    # ä¿å­˜æ¨¡å‹
                    filename = f"{model_name}.pkl"
                    joblib.dump(save_data, filename)

                    st.success(f"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: {filename}")

                    # æä¾›ä¸‹è½½
                    with open(filename, 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æ¨¡å‹æ–‡ä»¶",
                            data=f,
                            file_name=filename,
                            mime="application/octet-stream"
                        )

                except Exception as e:
                    st.error(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
        else:
            st.info("æ²¡æœ‰å¯ä¿å­˜çš„æ¨¡å‹")

    with col2:
        st.markdown('<h4>åŠ è½½å·²æœ‰æ¨¡å‹</h4>', unsafe_allow_html=True)

        uploaded_model = st.file_uploader(
            "ä¸Šä¼ æ¨¡å‹æ–‡ä»¶ (.pkl)",
            type=['pkl'],
            key="model_upload"
        )

        if uploaded_model:
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp_file:
                    tmp_file.write(uploaded_model.getvalue())
                    tmp_path = tmp_file.name

                # åŠ è½½æ¨¡å‹
                loaded_data = joblib.load(tmp_path)

                # æ›´æ–°session state
                if 'model' in loaded_data:
                    st.session_state.model = loaded_data['model']
                    st.success("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")

                    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                    st.write("**æ¨¡å‹ä¿¡æ¯**:")
                    info_cols = st.columns(2)

                    with info_cols[0]:
                        st.metric("æ¨¡å‹åç§°", loaded_data.get('model_name', 'æœªçŸ¥'))
                        st.metric("é—®é¢˜ç±»å‹", loaded_data.get('problem_type', 'æœªçŸ¥'))

                    with info_cols[1]:
                        st.metric("ç‰¹å¾æ•°é‡", len(loaded_data.get('feature_names', [])))
                        if 'timestamp' in loaded_data:
                            st.metric("åˆ›å»ºæ—¶é—´", loaded_data['timestamp'].strftime('%Y-%m-%d %H:%M'))

                    # åŠ è½½å…¶ä»–ç»„ä»¶
                    if 'scaler' in loaded_data:
                        st.session_state.scaler = loaded_data['scaler']
                        st.info("âœ… ç‰¹å¾ç¼©æ”¾å™¨å·²åŠ è½½")

                    if 'label_encoders' in loaded_data:
                        st.session_state.label_encoders = loaded_data['label_encoders']
                        st.info("âœ… æ ‡ç­¾ç¼–ç å™¨å·²åŠ è½½")

                    # æ›´æ–°feature_names
                    if 'feature_names' in loaded_data:
                        st.session_state.feature_names = loaded_data['feature_names']

                else:
                    st.error("âŒ æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_path)

            except Exception as e:
                st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")

    # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
    st.markdown("---")
    st.markdown('<h4>æ¨¡å‹æ€§èƒ½å¯¹æ¯”</h4>', unsafe_allow_html=True)

    if st.session_state.model is not None and hasattr(st.session_state, 'X_test') and hasattr(st.session_state,
                                                                                              'y_test'):
        # å¿«é€Ÿæµ‹è¯•å¤šä¸ªæ¨¡å‹
        if st.button("ğŸ”„ å¿«é€Ÿæ¨¡å‹å¯¹æ¯”"):
            with st.spinner("æ­£åœ¨å¯¹æ¯”å¤šä¸ªæ¨¡å‹..."):
                X_test = st.session_state.X_test
                y_test = st.session_state.y_test
                problem_type = st.session_state.problem_type

                # é€‰æ‹©æ¨¡å‹
                if problem_type == 'classification':
                    test_models = {
                        'éšæœºæ£®æ—': RandomForestClassifier(n_estimators=100, random_state=42),
                        'é€»è¾‘å›å½’': LogisticRegression(max_iter=1000, random_state=42),
                        'æ”¯æŒå‘é‡æœº': SVC(random_state=42),
                        'Kè¿‘é‚»': KNeighborsClassifier(),
                        'å†³ç­–æ ‘': DecisionTreeClassifier(random_state=42)
                    }
                    scoring_func = accuracy_score
                    scoring_name = "å‡†ç¡®ç‡"
                else:
                    test_models = {
                        'éšæœºæ£®æ—': RandomForestRegressor(n_estimators=100, random_state=42),
                        'çº¿æ€§å›å½’': LinearRegression(),
                        'æ”¯æŒå‘é‡å›å½’': SVR(),
                        'Kè¿‘é‚»å›å½’': KNeighborsRegressor(),
                        'å†³ç­–æ ‘å›å½’': DecisionTreeRegressor(random_state=42)
                    }
                    scoring_func = lambda y_true, y_pred: r2_score(y_true, y_pred)
                    scoring_name = "RÂ²åˆ†æ•°"

                # è®­ç»ƒå’Œè¯„ä¼°æ¯ä¸ªæ¨¡å‹
                results = []
                for name, model in test_models.items():
                    try:
                        model.fit(st.session_state.X_train, st.session_state.y_train)
                        y_pred = model.predict(X_test)
                        score = scoring_func(y_test, y_pred)
                        results.append({'æ¨¡å‹': name, scoring_name: score})
                    except Exception as e:
                        st.warning(f"{name} è®­ç»ƒå¤±è´¥: {str(e)}")

                if results:
                    results_df = pd.DataFrame(results).sort_values(scoring_name, ascending=False)

                    st.write(f"**æ¨¡å‹æ€§èƒ½å¯¹æ¯” ({scoring_name})**:")
                    st.dataframe(results_df, use_container_width=True)

                    # å¯è§†åŒ–å¯¹æ¯”
                    fig = px.bar(
                        results_df,
                        x='æ¨¡å‹',
                        y=scoring_name,
                        title=f'æ¨¡å‹æ€§èƒ½å¯¹æ¯”',
                        color=scoring_name,
                        color_continuous_scale='Viridis'
                    )
                    st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹æ‰èƒ½è¿›è¡Œå¯¹æ¯”")

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #7F8C8D;'>
        <p>ğŸ§¬ ç”Ÿç‰©æ•°æ®é¢„æµ‹ç³»ç»Ÿ | åŸºäºStreamlitæ„å»º | æ”¯æŒå¤šç§æœºå™¨å­¦ä¹ ç®—æ³•</p>
    </div>
    """,
    unsafe_allow_html=True
)